{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Scikit-Learn Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required steps\n",
    "### Pre-process\n",
    "    - [X] Categorical to Numeric\n",
    "    - [X] Clean Numeric Data\n",
    "    - [X] Outlier Detection\n",
    "    - [X] Data Transformation\n",
    "    - [X] Data Normalization\n",
    "    - [X] Dimensionality Reduction\n",
    "    \n",
    "### Training steps - models\n",
    "    - [ ] XGBoost Regression\n",
    "    - [ ] Lasso Regression\n",
    "    - [ ] ANN Regression\n",
    "    - [ ] Random Forest Regression\n",
    "    - [ ] ElasticNet\n",
    "    - [ ] Bayesian Ridge Regression\n",
    "    - [ ] LassoLarsIC Regression\n",
    "    \n",
    "### Stacking\n",
    "    - [ ] Picking one of the traning models as Meta-model\n",
    "    - [ ] Use the rest for training the evaluation set and test on the test set.\n",
    "    - [ ] Use Meta-model to predict the test set based on the trained models results.\n",
    "    \n",
    "### Ensembling [?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Implementation\n",
    "## Pre-process classes definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical columns to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import category_encoders as ce\n",
    "# categorical missing value imputer\n",
    "class CatToNum(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, dict_address, continuesVars, descreteVars_Ordinal, descreteVars_Nominal):\n",
    "        self.continuesVars = continuesVars\n",
    "        self.descreteVars_Ordinal = descreteVars_Ordinal\n",
    "        self.descreteVars_Nominal = descreteVars_Nominal\n",
    "        \n",
    "        fileName = dict_address\n",
    "        f = open(fileName,'r')\n",
    "        self.conversion_dict = json.loads(f.read())\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # we need the fit statement to accomodate the sklearn pipeline\n",
    "        des_nom_DF = X[self.descreteVars_Nominal]\n",
    "        # Map Nominal Categorical data to Numerical\n",
    "        cat_nom_DF = des_nom_DF.fillna('NULL').astype(str)\n",
    "        self.ce_binary = ce.BinaryEncoder()\n",
    "        self.ce_binary.fit(cat_nom_DF)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "        conDF = X[self.continuesVars]\n",
    "        des_ord_DF = X[self.descreteVars_Ordinal]\n",
    "        des_nom_DF = X[self.descreteVars_Nominal]\n",
    "        \n",
    "        # Map Ordinal Categorical data to Numerical\n",
    "        cat_ord_DF_numerical = des_ord_DF.copy()\n",
    "        for feature in self.conversion_dict:\n",
    "            temp_dict = conversion_dict[feature]\n",
    "            if ('NA' in temp_dict): # Replace 'NA' with np.nan\n",
    "                temp_dict[np.nan] = temp_dict.pop('NA')\n",
    "            cat_ord_DF_numerical[feature] = des_ord_DF[feature].map(temp_conversion_dict)\n",
    "            \n",
    "        totalDF[self.descreteVars_Ordinal] = cat_ord_DF_numerical\n",
    "            \n",
    "        # Map Nominal Categorical data to Numerical\n",
    "        cat_nom_DF = des_nom_DF.fillna('NULL').astype(str)\n",
    "        cat_nom_DF_numerical = self.ce_binary.transform(cat_nom_DF)\n",
    "        totalDF[self.descreteVars_Nominal] = cat_nom_DF_numerical\n",
    "        \n",
    "        cols_to_drop = [x for x in list(cat_nom_DF_numerical) if ('_0' in x)]\n",
    "        totalDF.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        return totalDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanNum(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, drop_thresh=0.8):\n",
    "        self.drop_thresh = drop_thresh\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        train_df = X.copy()\n",
    "        # Remove columns with dominance bigger than a threshold\n",
    "        self.drop_list = []\n",
    "        for feature in train_df:\n",
    "            col_df = train_df[feature]\n",
    "            count_nan = col_df.isnull().sum()\n",
    "            nan_ratio = count_nan/len(col_df)   \n",
    "            repeats = train_df.pivot_table(index=[feature], aggfunc='size').sort_values()\n",
    "            max_repeat_ratio = repeats.max()/len(col_df)\n",
    "            if (nan_ratio>self.drop_thresh or max_repeat_ratio>self.drop_thresh):\n",
    "                self.drop_list.append(feature)\n",
    "\n",
    "        # Replace null values with average (or mode) of the train columns\n",
    "        self.cols_average = df.mean(axis = 1) \n",
    "        self.cols_mode = df.mode(axis = 1)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, measure='mean'):\n",
    "        totalDF = X.copy()\n",
    "        \n",
    "        # Replace null values with average (or mode) of the train columns\n",
    "        for col in totalDF:\n",
    "            if (measure=='mean'):\n",
    "                totalDF[col].fillna(self.cols_average[col], inplace=True)\n",
    "            if (measure=='mode'):\n",
    "                totalDF[col].fillna(self.cols_mode[col], inplace=True)\n",
    "        \n",
    "        # Remove columns with dominance bigger than a threshold\n",
    "        totalDF.drop(self.drop_list, axis=1, inplace=True)\n",
    "\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutlierDetection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "        # Function to Detection Outlier on one-dimentional datasets.\n",
    "    def find_anomalies(data):\n",
    "        anomalies_idx = []\n",
    "        # Set upper and lower limit to 3 standard deviation\n",
    "        data_std = data.std()\n",
    "        data_mean = data.mean()\n",
    "        anomaly_cut_off = data_std * 3\n",
    "\n",
    "        lower_limit  = data_mean - anomaly_cut_off \n",
    "        upper_limit = data_mean + anomaly_cut_off\n",
    "        # Generate outliers\n",
    "        for idx in range(len(data)):\n",
    "            outlier = data[idx]\n",
    "            if outlier > upper_limit or outlier < lower_limit:\n",
    "                anomalies_idx.append(idx)\n",
    "        return anomalies_idx\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        train_df = X.copy()\n",
    "        outliers_full_list = []\n",
    "        for feature in train_df:\n",
    "            outliers_full_list = outliers_full_list + find_anomalies(train_df[feature].values)\n",
    "\n",
    "        self.outliers_unique = list(set(outliers_full_list))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "        totalDF.drop(outliers_unique, inplace=True)\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation (Box-Cox transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "\n",
    "class DataTransformation(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None, thresh=0.75, lam=0.15):\n",
    "        self.lam = lam\n",
    "        train_df = X.copy\n",
    "        # Check the skew of all numerical features\n",
    "        skewed_feats = skew(train_df).sort_values(ascending=False)\n",
    "        skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "        skewness = skewness[abs(skewness) > thresh]\n",
    "        self.skewed_features_list = list(skewness)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "        skewed_features = totalDF[self.skewed_features_list]\n",
    "        for feat in skewed_features:\n",
    "            #all_data[feat] += 1\n",
    "            totalDF[feat] = boxcox1p(totalDF[feat], self.lam)\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "There is no need to define a specific class for data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "I am thinking there is no need for dimensionality reduction at the moment. But I may change my mind later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model, train, y_train):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps - models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'house-prices-advanced-regression-techniques/train.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_file = 'house-prices-advanced-regression-techniques/test.csv'\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "descreteVars_Nominal = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour', 'LotConfig', 'Neighborhood',\n",
    "                        'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                        'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'Electrical',\n",
    "                        'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "\n",
    "descreteVars_Ordinal = ['LotShape', 'Utilities', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual',\n",
    "                        'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "                        'KitchenQual','Functional',  'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                        'PavedDrive', 'PoolQC', 'Fence']\n",
    "\n",
    "resultVar = ['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "continuesVars = list(set(list(train_df)) - set(descreteVars_Nominal) - set(descreteVars_Ordinal) - set(resultVar))\n",
    "\n",
    "dict_address='cat_ord_dict.txt'\n",
    "\n",
    "\n",
    "X = train_df.drop(resultVar, axis=1)\n",
    "y = train_df[resultVar]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(CatToNum(dict_address, continuesVars, descreteVars_Ordinal, descreteVars_Nominal), CleanNum(), OutlierDetection(), DataTransformation(), RobustScaler(), Lasso(alpha =0.0005, random_state=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = X\n",
    "# y_train = y\n",
    "# score = rmsle_cv(lasso, train, y_train)\n",
    "# print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
