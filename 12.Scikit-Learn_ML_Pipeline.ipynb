{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Scikit-Learn Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required steps\n",
    "### Pre-process\n",
    "    - [X] Categorical to Numeric\n",
    "    - [X] Clean Numeric Data\n",
    "    - [X] Outlier Detection\n",
    "    - [X] Data Transformation\n",
    "    - [X] Data Normalization\n",
    "    - [X] Dimensionality Reduction\n",
    "    \n",
    "### Training steps - models\n",
    "    - [X] Kernel Ridge\n",
    "    - [X] XGBoost Regression\n",
    "    - [X] Lasso Regression\n",
    "    - [ ] ANN Regression\n",
    "    - [X] Random Forest Regression\n",
    "    - [X] ElasticNet\n",
    "    - [X] Bayesian Ridge Regression\n",
    "    - [X] LassoLarsIC Regression\n",
    "    - [X] Gradient Boosting Regression\n",
    "    \n",
    "### Stacking\n",
    "    - [ ] Picking one of the traning models as Meta-model\n",
    "    - [ ] Use the rest for training the evaluation set and test on the test set.\n",
    "    - [ ] Use Meta-model to predict the test set based on the trained models results.\n",
    "    \n",
    "### Ensembling [?]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## Implementation\n",
    "## Pre-process classes definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical columns to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import category_encoders as ce\n",
    "# categorical missing value imputer\n",
    "class CatToNum(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, dict_address, continuesVars, descreteVars_Ordinal, descreteVars_Nominal):\n",
    "        self.continuesVars = continuesVars\n",
    "        self.descreteVars_Ordinal = descreteVars_Ordinal\n",
    "        self.descreteVars_Nominal = descreteVars_Nominal\n",
    "        \n",
    "        fileName = dict_address\n",
    "        f = open(fileName,'r')\n",
    "        self.conversion_dict = json.loads(f.read())\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # we need the fit statement to accomodate the sklearn pipeline\n",
    "        des_nom_DF = X[self.descreteVars_Nominal]\n",
    "        # Map Nominal Categorical data to Numerical\n",
    "        cat_nom_DF = des_nom_DF.fillna('NULL').astype(str)\n",
    "        self.ce_binary = ce.BinaryEncoder()\n",
    "        self.ce_binary.fit(cat_nom_DF)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "        conDF = X[self.continuesVars]\n",
    "        des_ord_DF = X[self.descreteVars_Ordinal]\n",
    "        des_nom_DF = X[self.descreteVars_Nominal]\n",
    "        \n",
    "        # Map Ordinal Categorical data to Numerical\n",
    "        cat_ord_DF_numerical = des_ord_DF.copy()\n",
    "        for feature in self.conversion_dict:\n",
    "            temp_dict = self.conversion_dict[feature]\n",
    "            if ('NA' in temp_dict): # Replace 'NA' with np.nan\n",
    "                temp_dict[np.nan] = temp_dict.pop('NA')\n",
    "            cat_ord_DF_numerical[feature] = des_ord_DF[feature].map(temp_dict)\n",
    "            \n",
    "        totalDF[self.descreteVars_Ordinal] = cat_ord_DF_numerical\n",
    "            \n",
    "        # Map Nominal Categorical data to Numerical\n",
    "        cat_nom_DF = des_nom_DF.fillna('NULL').astype(str)\n",
    "        cat_nom_DF_numerical = self.ce_binary.transform(cat_nom_DF)\n",
    "        totalDF = pd.concat([totalDF, cat_nom_DF_numerical], axis=1)\n",
    "        totalDF.drop(self.descreteVars_Nominal, axis=1, inplace=True)\n",
    "        cols_to_drop = [x for x in list(cat_nom_DF_numerical) if ('_0' in x)]\n",
    "        totalDF.drop(cols_to_drop, axis=1, inplace=True)\n",
    "\n",
    "        return totalDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CleanNum(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, measure='mean', drop_thresh=0.8):\n",
    "        self.measure = measure\n",
    "        self.drop_thresh = drop_thresh\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        train_df = X.copy().astype(float)\n",
    "        # Remove columns with dominance bigger than a threshold\n",
    "        self.drop_list = []\n",
    "        for feature in train_df:\n",
    "            col_df = train_df[feature]\n",
    "            count_nan = col_df.isnull().sum()\n",
    "            nan_ratio = count_nan/len(col_df)   \n",
    "            repeats = train_df.pivot_table(index=[feature], aggfunc='size').sort_values()\n",
    "            max_repeat_ratio = repeats.max()/len(col_df)\n",
    "            if (nan_ratio>self.drop_thresh or max_repeat_ratio>self.drop_thresh):\n",
    "                self.drop_list.append(feature)\n",
    "\n",
    "        # Replace null values with average (or mode) of the train columns\n",
    "        self.cols_average = train_df.mean(axis = 0)\n",
    "        self.cols_mode = train_df.mode(axis = 0)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy().astype(float)\n",
    "        \n",
    "        # Replace null values with average (or mode) of the train columns\n",
    "        for col in totalDF:\n",
    "            if (self.measure=='mean'):\n",
    "                totalDF[col] = totalDF[col].fillna(self.cols_average[col])\n",
    "            if (self.measure=='mode'):\n",
    "                totalDF[col] = totalDF[col].fillna(self.cols_mode[col])\n",
    "        \n",
    "        # Remove columns with dominance bigger than a threshold\n",
    "        totalDF.drop(self.drop_list, axis=1, inplace=True)\n",
    "\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OutlierDetection(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "        # Function to Detection Outlier on one-dimentional datasets.\n",
    "    def find_anomalies(self,data):\n",
    "        anomalies_idx = []\n",
    "        # Set upper and lower limit to 3 standard deviation\n",
    "        data_std = data.std()\n",
    "        data_mean = data.mean()\n",
    "        anomaly_cut_off = data_std * 3\n",
    "\n",
    "        lower_limit  = data_mean - anomaly_cut_off \n",
    "        upper_limit = data_mean + anomaly_cut_off\n",
    "        # Generate outliers\n",
    "        for idx in range(len(data)):\n",
    "            outlier = data[idx]\n",
    "            if outlier > upper_limit or outlier < lower_limit:\n",
    "                anomalies_idx.append(idx)\n",
    "        return anomalies_idx\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        train_df = X.copy()\n",
    "        outliers_full_list = []\n",
    "        for feature in train_df:\n",
    "            outliers_full_list = outliers_full_list + self.find_anomalies(train_df[feature].values)\n",
    "\n",
    "        self.outliers_unique = list(set(int(outliers_full_list)))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "        totalDF.drop(self.outliers_unique, inplace=True)\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation (Box-Cox transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import norm, skew\n",
    "\n",
    "class DataTransformation(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None, thresh=0.75, lam=0.15):\n",
    "        self.lam = lam\n",
    "        train_df = X.copy()\n",
    "        # Check the skew of all numerical features\n",
    "#         print(type(skew(train_df)))\n",
    "        skewed_feats = train_df.apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "#         print(type(skewed_feats ))\n",
    "        skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "        skewness = skewness[abs(skewness) > thresh]\n",
    "        self.skewed_features_idx_list = skewness.index\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        totalDF = X.copy()\n",
    "#         skewed_features = totalDF[self.skewed_features_list]\n",
    "        for feat_idx in self.skewed_features_idx_list:\n",
    "            #all_data[feat] += 1\n",
    "            totalDF[feat_idx] = boxcox1p(totalDF[feat_idx], self.lam)\n",
    "        return totalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalization\n",
    "There is no need to define a specific class for data normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction\n",
    "I am thinking there is no need for dimensionality reduction at the moment. But I may change my mind later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model, train, y_train):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training steps - models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = 'house-prices-advanced-regression-techniques/train.csv'\n",
    "train_df = pd.read_csv(train_file)\n",
    "test_file = 'house-prices-advanced-regression-techniques/test.csv'\n",
    "test_df = pd.read_csv(test_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "descreteVars_Nominal = ['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour', 'LotConfig', 'Neighborhood',\n",
    "                        'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
    "                        'Exterior2nd', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'Electrical',\n",
    "                        'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "\n",
    "descreteVars_Ordinal = ['LotShape', 'Utilities', 'LandSlope', 'ExterQual', 'ExterCond', 'BsmtQual',\n",
    "                        'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "                        'KitchenQual','Functional',  'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                        'PavedDrive', 'PoolQC', 'Fence']\n",
    "\n",
    "resultVar = ['SalePrice']\n",
    "\n",
    "\n",
    "\n",
    "continuesVars = list(set(list(train_df)) - set(descreteVars_Nominal) - set(descreteVars_Ordinal) - set(resultVar))\n",
    "\n",
    "dict_address='cat_ord_dict.txt'\n",
    "\n",
    "\n",
    "X = train_df.drop(resultVar, axis=1)\n",
    "y = train_df[resultVar]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_names = ['KernelRidge', 'ElasticNet', 'Lasso', 'GradientBoostingRegressor', 'BayesianRidge', 'LassoLarsIC', 'RandomForestRegressor', 'XGBRegressor']\n",
    "models_list = [KernelRidge(), ElasticNet(), Lasso(), GradientBoostingRegressor(), BayesianRidge(), LassoLarsIC(), RandomForestRegressor(), XGBRegressor()]\n",
    "\n",
    "KR_param_grid = {'alpha': 0.1, 'coef0': 100, 'degree': 1, 'gamma': None, 'kernel': 'polynomial'}\n",
    "EN_param_grid = {'alpha': 0.001, 'copy_X': True, 'l1_ratio': 0.6, 'fit_intercept': True, 'normalize': False, \n",
    "                         'precompute': False, 'max_iter': 300, 'tol': 0.001, 'selection': 'random', 'random_state': None}\n",
    "LASS_param_grid = {'alpha': 0.0005, 'copy_X': True, 'fit_intercept': True, 'normalize': False, 'precompute': False, \n",
    "                    'max_iter': 300, 'tol': 0.01, 'selection': 'random', 'random_state': None}\n",
    "GB_param_grid = {'loss': 'huber', 'learning_rate': 0.1, 'n_estimators': 300, 'max_depth': 3, \n",
    "                                        'min_samples_split': 0.0025, 'min_samples_leaf': 5}\n",
    "BR_param_grid = {'n_iter': 200, 'tol': 0.00001, 'alpha_1': 0.00000001, 'alpha_2': 0.000005, 'lambda_1': 0.000005, \n",
    "                 'lambda_2': 0.00000001, 'copy_X': True}\n",
    "LL_param_grid = {'criterion': 'aic', 'normalize': True, 'max_iter': 100, 'copy_X': True, 'precompute': 'auto', 'eps': 0.000001}\n",
    "RFR_param_grid = {'n_estimators': 50, 'max_features': 'auto', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2}\n",
    "XGB_param_grid = {'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 300, 'booster': 'gbtree', 'gamma': 0, 'reg_alpha': 0.1,\n",
    "                  'reg_lambda': 0.7, 'max_delta_step': 0, 'min_child_weight': 1, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.2,\n",
    "                  'scale_pos_weight': 1}\n",
    "params_grid = [KR_param_grid, EN_param_grid, LASS_param_grid, GB_param_grid, BR_param_grid, LL_param_grid, RFR_param_grid, XGB_param_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_rmse(model, X, y):\n",
    "    return (np.sqrt(mean_squared_error(y, model.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KernelRidge\n",
      "{'alpha': 0.1, 'coef0': 100, 'degree': 1, 'gamma': None, 'kernel': 'polynomial'}\n",
      "Normal KernelRidge\n",
      "Train rmse: \n",
      "40477.34158383138\n",
      "Validation rmse: \n",
      "33752.360766751575\n",
      "KernelRidge with transformed skewed columns\n",
      "Train rmse: \n",
      "33964.60910631942\n",
      "Validation rmse: \n",
      "35648.871174359774\n",
      "-----------------------------------------------------\n",
      "ElasticNet\n",
      "{'alpha': 0.001, 'copy_X': True, 'l1_ratio': 0.6, 'fit_intercept': True, 'normalize': False, 'precompute': False, 'max_iter': 300, 'tol': 0.001, 'selection': 'random', 'random_state': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal ElasticNet\n",
      "Train rmse: \n",
      "41325.30920639971\n",
      "Validation rmse: \n",
      "34810.30493615326\n",
      "ElasticNet with transformed skewed columns\n",
      "Train rmse: \n",
      "33899.27720857602\n",
      "Validation rmse: \n",
      "35853.99645104794\n",
      "-----------------------------------------------------\n",
      "Lasso\n",
      "{'alpha': 0.0005, 'copy_X': True, 'fit_intercept': True, 'normalize': False, 'precompute': False, 'max_iter': 300, 'tol': 0.01, 'selection': 'random', 'random_state': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Lasso\n",
      "Train rmse: \n",
      "41406.27524995679\n",
      "Validation rmse: \n",
      "34917.889532243666\n",
      "Lasso with transformed skewed columns\n",
      "Train rmse: \n",
      "33898.335726322875\n",
      "Validation rmse: \n",
      "35887.114249230624\n",
      "-----------------------------------------------------\n",
      "GradientBoostingRegressor\n",
      "{'loss': 'huber', 'learning_rate': 0.1, 'n_estimators': 300, 'max_depth': 3, 'min_samples_split': 0.0025, 'min_samples_leaf': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal GradientBoostingRegressor\n",
      "Train rmse: \n",
      "29302.202100613005\n",
      "Validation rmse: \n",
      "33234.63274659266\n",
      "GradientBoostingRegressor with transformed skewed columns\n",
      "Train rmse: \n",
      "12547.39910193762\n",
      "Validation rmse: \n",
      "24410.560105373817\n",
      "-----------------------------------------------------\n",
      "BayesianRidge\n",
      "{'n_iter': 200, 'tol': 1e-05, 'alpha_1': 1e-08, 'alpha_2': 5e-06, 'lambda_1': 5e-06, 'lambda_2': 1e-08, 'copy_X': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal BayesianRidge\n",
      "Train rmse: \n",
      "39673.49024145989\n",
      "Validation rmse: \n",
      "32803.34106049047\n",
      "BayesianRidge with transformed skewed columns\n",
      "Train rmse: \n",
      "34136.259176299565\n",
      "Validation rmse: \n",
      "35605.25461046637\n",
      "-----------------------------------------------------\n",
      "LassoLarsIC\n",
      "{'criterion': 'aic', 'normalize': True, 'max_iter': 100, 'copy_X': True, 'precompute': 'auto', 'eps': 1e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal LassoLarsIC\n",
      "Train rmse: \n",
      "39190.286795731154\n",
      "Validation rmse: \n",
      "33867.8805962962\n",
      "LassoLarsIC with transformed skewed columns\n",
      "Train rmse: \n",
      "36237.789598564945\n",
      "Validation rmse: \n",
      "37736.43770937154\n",
      "-----------------------------------------------------\n",
      "RandomForestRegressor\n",
      "{'n_estimators': 50, 'max_features': 'auto', 'max_depth': None, 'min_samples_split': 5, 'min_samples_leaf': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal RandomForestRegressor\n",
      "Train rmse: \n",
      "38389.95616432039\n",
      "Validation rmse: \n",
      "39691.808804357446\n",
      "RandomForestRegressor with transformed skewed columns\n",
      "Train rmse: \n",
      "14968.822865022277\n",
      "Validation rmse: \n",
      "26673.488684543707\n",
      "-----------------------------------------------------\n",
      "XGBRegressor\n",
      "{'max_depth': 3, 'learning_rate': 0.1, 'n_estimators': 300, 'booster': 'gbtree', 'gamma': 0, 'reg_alpha': 0.1, 'reg_lambda': 0.7, 'max_delta_step': 0, 'min_child_weight': 1, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.2, 'scale_pos_weight': 1}\n",
      "[01:24:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[01:24:28] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Normal XGBRegressor\n",
      "Train rmse: \n",
      "39965.45639953617\n",
      "Validation rmse: \n",
      "42260.85232911142\n",
      "XGBRegressor with transformed skewed columns\n",
      "Train rmse: \n",
      "10914.988945978688\n",
      "Validation rmse: \n",
      "24235.476100168296\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "original_test_file = 'house-prices-advanced-regression-techniques/test.csv'\n",
    "original_test_df = pd.read_csv(original_test_file)\n",
    "id_col = original_test_df['Id']\n",
    "\n",
    "for i in range(len(models_list)):\n",
    "    print(models_names[i])\n",
    "    model = models_list[i]\n",
    "    params = params_grid[i]\n",
    "    print(params)\n",
    "    pipeline = make_pipeline(CatToNum(dict_address, continuesVars, descreteVars_Ordinal, descreteVars_Nominal), CleanNum(), RobustScaler(), model.set_params(**params))\n",
    "    pipeline_transformed = make_pipeline(CatToNum(dict_address, continuesVars, descreteVars_Ordinal, descreteVars_Nominal), CleanNum(), DataTransformation(), RobustScaler(), model.set_params(**params))\n",
    "\n",
    "    pipeline.fit(X_train, y_train)    \n",
    "    pipeline_transformed.fit(X_train, y_train)    \n",
    "    \n",
    "    print('Normal ' + models_names[i])\n",
    "    print('Train rmse: ')\n",
    "    print(cal_rmse(pipeline, X_train, y_train))\n",
    "    print('Validation rmse: ')\n",
    "    print(cal_rmse(pipeline, X_val, y_val))\n",
    "    print(models_names[i]+' with transformed skewed columns')\n",
    "    print('Train rmse: ')\n",
    "    print(cal_rmse(pipeline_transformed, X_train, y_train))\n",
    "    print('Validation rmse: ')\n",
    "    print(cal_rmse(pipeline_transformed, X_val, y_val))\n",
    "    print('-----------------------------------------------------')\n",
    "    \n",
    "    Y_pred = pipeline.predict(test_df)\n",
    "    result_df = pd.concat([id_col, pd.DataFrame(Y_pred, columns=['SalePrice'])], axis=1)\n",
    "    result_df.to_csv('Results/'+models_names[i]+'.csv', index=False)\n",
    "    \n",
    "    \n",
    "    Y_pred_transformed = pipeline_transformed.predict(test_df)\n",
    "    result_df = pd.concat([id_col, pd.DataFrame(Y_pred_transformed, columns=['SalePrice'])], axis=1)\n",
    "    result_df.to_csv('Results/'+models_names[i]+'_transformed.csv', index=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
